# 为什么要使用消息队列

## 解耦
多个系统要相互通知，中间引入一个消息队列，启用多个消费者消费，省很多精力

## 异步
用户发起请求，请求对应着很多耗时的操作（比如操作BCD三个数据库，各需0.5秒，加起来1.5秒），用户体验不太好。用户的操作请求先进入消息队列，后台通过异步的方式慢慢处理，及时响应用户。

## 削峰
一个系统某段时间并发访问特多多，系统基于MySQL，一般每秒5k个请求，mysql就被打死了，导致系统崩溃，后续也就不用使用了。

高峰期一过，每秒操作的请求也就几十，对整个系统没有什么压力

如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。

这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。


# 消息队列有什么优缺点

## 系统可用性降低
系统引入的外部依赖越多，越容易出问题。本身ABC三个系统调用，ABC不挂就行，现在加了mq，mq挂了怎么办。**需要保证消息队列的高可用**

## 系统复杂度提升
系统中添加了消息队列，如何**保证消息不被重复消费，消息丢失了怎么办？又如何保证消息能按顺序消费**

## 系统一致性
A系统处理完直接返回成功了，用户以为请求成功了，但是后台BCD等系统还在异步处理，如果BCD三个系统中，BD写入成功了，C失败了，这样就造成了数据不一致

## 各种MQ对比，为什么选择activeMQ

rocketMQ和Kfaka都是处理海量数据的，没达到那个量
rabbitMQ不是java语言写的，真出了问题没人搞，尽管社区很活跃
ActiveMQ java写的，性能也还不错，响应在ms级。


# 如何保证消息队列的高可用

ActiveMQ 的高可用一般使用zookeeper和levelDb来保证
其负载均衡也很简单，在配置文件中多个节点互相链接就行
#### TODO
-----

## RabbitMQ的高可用性
RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的

RabbitMQ有三种模式：**单机模式、普通集群模式、镜像集群模式**

### 单机模式
测试用

### 集群模式
普通集群模式，在多个机器上启动多个RabbitMQ实例，你创建的queue只会存在于一个RabbitMQ实例上，但是每个实例都同步queue的元数据（通过原数据可以找到queue所在的实例）。消费的时候，如果连接到了另一个实例，这个实例会从queue所在的实例拉取数据

这种方式有很大的缺点：

- MQ集群内部产生大量的数据传输，影响性能
- queue所在的实例挂了，数据就丢了

这种方式确实很麻烦，也不怎么好，没做到所谓的**分布式**，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。

而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 RabbitMQ 落地存储消息的话，**消息不一定会丢**，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。

所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性，这方案主要是**提高吞吐量**的，就是说让集群中多个节点来服务某个 queue 的读写操作。

### 镜像集群模式（高可用）
在镜像集群模式下，创建的queue，无论queue里的消息还是元数据都会存在于多个实例中，每个实例拥有queue数据的**完整镜像**，每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。

不过，性能开销太大了，消息需要同步到所有机器上，同时，还**不是分布式的**。某个queue负载很重，加了机器，新加的机器还是包含queue的全部数据，没办法**线性扩展**。

对于镜像集群而言，当某个queue负载过重，可能会导致集群雪崩，那么如何来减少集群雪崩呢？我们可以通过HA的同步策略来实现

HA的同步策略如下：


HA-mode | HA-params | 说明
-- | -- | --
all | 空 | 镜像队列将会在整个集群中复制。当一个新的节点加入后，也会在这个节点上复制一份。
exactly	|count|	镜像队列将会在集群上复制count份。如果集群数量少于count时候，队列会复制到所有节点上。如果大于Count集群，有一个节点crash后，新进入节点也不会做新的镜像。（可以阻止集群雪崩）
nodes|node name	|镜像队列会在nodename中复制。如果这个名称不是集群中的一个，这不会触发错误。如果在这个node list中没有一个节点在线，那么这个queue会被声明在client连接的节点。

## Kfaka高可用

# 如何保证消息不被重复消费

## 
首先，比如 RabbitMQ、RocketMQ、Kafka，都有可能会出现消息重复消费的问题，正常。因为这问题通常不是 MQ 自己保证的，是由我们开发来保证的。挑一个 Kafka 来举个例子，说说怎么重复消费吧。

Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。

但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。

其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么**保证幂等性**。

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

# 如何保证消息的可靠性传输（保证不丢消息）

消息丢失有三种情况，无非是出现在生产者、消息队列、消费者

##  生产者丢失消息
## 消息队列丢失消息
## 消费者丢失消息
